<img src="https://raw.githubusercontent.com/ElizaLo/Data-Science/master/img/Hyperparameters.png" width="1050" height="150"/>

# âš™ï¸ Hyperparameters tuning

## ğŸ“° Articles

- [Hyperparameter Tuning in Python: a Complete Guide](https://neptune.ai/blog/hyperparameter-tuning-in-python-complete-guide)

## ğŸ› ï¸ Tools

| Title | Description, Information |
| :---:         |          :--- |
|[Weights & Biases](https://docs.wandb.ai/)|<p>Weights & Biases is the machine learning platform for developers to build better models faster. Use W&B's lightweight, interoperable tools to quickly track experiments, version and iterate on datasets, evaluate model performance, reproduce models, visualize results and spot regressions, and share findings with colleagues.</p><ul><li> :octocat: [wandb](https://github.com/wandb/wandb)</li></ul>|
|[Aim](https://github.com/aimhubio/aim)|Aim ğŸ’« â€” easy-to-use and performant open-source ML experiment tracker.|
|[Weight Watcher](https://github.com/CalculatedContent/WeightWatcher)|WeightWatcher (WW): is an open-source, diagnostic tool for analyzing Deep Neural Networks (DNN), without needing access to training or even test data.|

# Parametrization 

They have discovered new **parameterization (Î¼P)** that the best hyperparameters for the smaller models are the same as the best for the larger ones with the same architecture. It has allowed researchers to optimize large models at a fraction of the cost. 
